"""Анализ алгоритмов."""

# # Модель вычислений RAM

# Разработка машинно-независимых алгоритмов основывается на гипотетическом компьютере, называемом машиной с произвольным доступом к памяти (Random Access Machine), или RАМ-машиной. Согласно этой модели наш компьютер работает таким образом:
# * для исполнения любой простой операции ( +, *, -, =, if, call) требуется ровно одинвременной шаг;
# * циклы и подпрограммы не считаются простыми операциями, а состоят из нескольких простых операций.
# * каждое обращение к памяти занимает один временной шаг.

# Алгоритмы можно изучать и анализировать, не прибегая к использованию конкретного языка программирования или компьютерной платформы.

# Чтобы понять, что означает наилучший, наихудший и средний случай сложности алгоритма (т. е. время его исполнения в соответствующем случае), нужно рассмотреть исполнение алгоритма на всех возможных экземплярах входных данных.
#
# * сложность алгоритма в наихудшем случае - это функция, определяемая максимальным количеством шагов, требуемых для обработки любого входного экземпляра размером n. Этот случай отображается кривой, проходящей через самую высшую точку каждого столбца;
# * сложность алгоритма в наилучшем случае - это функция, определяемая минимальным количеством шагов, требуемых для обработки любого входного экземпляра размером n. Этот случай отображается кривой, проходящей через самую низшую точку каждого столбца;
# * сложность алгоритма в среднем случае, или его ожидаемое время, - это функция, определяемая средним количеством шагов, требуемых для обработки всех экземпляров размером n.
#
# На практике обычно наиболее важной является оценка сложности алгоритма в наихудшем случае.

# # Асимптотические («Big Oh») обозначения

# Намного легче работать с верхней и нижней границами функций временной сложности, используя для этого асимптотические («Big Oh») обозначения. Асимптотические обозначения позволяют упростить анализ, поскольку игнорируют детали, которые не влияют на сравнение эффективности алгоритмов.
#
# * f(n) = О(g(n)) означает, что функция f(n) ограничена сверху функцией с • g(n)
# * f(n) = Ω(g(n)) означает, что функция f(n) ограничена снизу функцией с • g(n)
# * f(n) = Θ(g(n)) означает, что функция f(n) ограничена сверху функцией c1 • g(n), а снизу функцией c2 • g(n) для всех n >= n0
#
# Анализ наихудшего случая и асимптотические обозначения являются инструментами, которые существенно упрощают задачу сравнения эффективности алгоритмов.

# # Скорость роста

# * время исполнения всех этих алгоритмов примерно одинаково для значений n = 1О;
# * любой алгоритм с временем исполнения n! становится бесполезным для значений n >= 20;
# * диапазон алгоритмов с временем исполнения 2^n несколько шире, но они также становятся непрактичными для значений n > 40;
# * алгоритмы с квадратичным временем исполнения n^2 применяются при n <= 1О ООО, после чего их производительность начинает резко ухудшаться. Эти алгоритмы, скорее всего, будут бесполезны для значений n > 1 ООО ООО;
# * алгоритмы с линейным и логарифмическим временем исполнения остаются полезными при обработке миллиарда элементов;
# * алгоритм O(log n) без труда обрабатывает любое вообразимое количество элементов.
#

# # Отношения доминирования

# Функция с более быстрым темпом роста доминирует над менее быстро растущей функцией.
#
# * **Функции-константы f(n) = 1**
#
# 	Такие функции могут измерять трудоемкость сложения двух чисел, распечатывания текста государственного гимна или рост таких функций, как f(n) = min(n, 100). По большому счету зависимость от параметра n отсутствует.
#
# * **Логарифмические функции f(n) = log n**
#
# 	Логарифмическая временная сложность проявляется в таких алгоритмах, как двоичный поиск. С увеличением n эти функции возрастают довольно медленно, но быстрее, чем функции-константы (которые вообще не возрастают).
#
# * **Линейные функции f(n) = n**
#
# 	Такие функции измеряют трудоемкость просмотра каждого элемента в массиве элементов один раз (или два раза, или десять раз) например, для определения наибольшего или наименьшего элемента или для вычисления среднего значения.
#
# * **Суперлинейные функции f(n) = n * log n**
#
# 	Этот важный класс функций возникает в таких алгоритмах, как quicksort и mergesort. Эти функции возрастают лишь немного быстрее, чем линейные, но достаточно быстро, чтобы подняться к более высокому классу доминирования.
#
# * **Квадратичные функции f(n) = n^2**
#
# 	Эти функции измеряют трудоемкость просмотра большинства или всех пар элементов в универсальном множестве из n элементов. Они возникают в таких алгоритмах, как сортировка вставками или сортировка методом выбора.
#
# * **Кубические функции f(n) = n^3**
#
# 	Эти функции перечисляют все триады элементов в универсальном множестве из n элементов. Они также возникают в определенных алгоритмах динамического программирования.
#
# * **Показательные функции f(n) = с^n**, константа с > 1
#
# 	Эти функции возникают при перечислении всех подмножеств множества из n элементов. Экспоненциальные алгоритмы быстро становятся бесполезными с увеличением количества элементов n.
#
# * **Факториальные функции f(n) = n!**
#
# 	Факториальные функции определяют все перестановки n элементов.
#
